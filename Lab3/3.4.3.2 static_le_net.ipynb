{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed50329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import psutil\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d680d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1. LOAD AND NORMALIZE CIFAR10\"\"\"\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "testsize = len(testset)\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b987983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1.1 SHOW SOME TRAINING IMAGES JUST FOR FUN\"\"\"\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4c20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2. DEFINE A CONVOLUTIONAL NEURAL NETWORK\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model_fp32 = Net()\n",
    "\n",
    "\"\"\"3. DEFINE A LOSS FUNCTION AND OPTIMIZER\"\"\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_fp32.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4eadff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.179\n",
      "[1,  4000] loss: 0.282\n",
      "[1,  6000] loss: 0.195\n",
      "[1,  8000] loss: 0.170\n",
      "[1, 10000] loss: 0.134\n",
      "[1, 12000] loss: 0.115\n",
      "[1, 14000] loss: 0.109\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\"\"\"4. TRAIN THE NETWORK\"\"\"\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "            \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_fp32(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fb7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.77 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"On the Whole Data set\"\"\"\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model_fp32(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f2aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0     is: 98.6 %\n",
      "Accuracy for class 1     is: 99.4 %\n",
      "Accuracy for class 2     is: 92.1 %\n",
      "Accuracy for class 3     is: 97.5 %\n",
      "Accuracy for class 4     is: 98.4 %\n",
      "Accuracy for class 5     is: 97.1 %\n",
      "Accuracy for class 6     is: 98.7 %\n",
      "Accuracy for class 7     is: 97.4 %\n",
      "Accuracy for class 8     is: 92.7 %\n",
      "Accuracy for class 9     is: 95.3 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/ao/quantization/observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/ao/quantization/observer.py:1107: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 249.735\n",
      "model:  int8  \t Size (KB): 75.077\n",
      "3.33 times smaller\n",
      "Test accuracy: 0.276183\n",
      "Inference complete in 0m 57s\n",
      "report mem usage 261.824 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Accuracy per Class\"\"\"\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model_fp32(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "\n",
    "def validation_model(model, criterion, optimizer, device):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    running_loss = 0.0\n",
    "    time_start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    time_elapsed = (time.perf_counter() - time_start)\n",
    "    \n",
    "    val_acc = running_corrects.double() / testsize\n",
    "    print('Test accuracy: {:4f}'.format(val_acc))\n",
    "    \n",
    "    print('Inference complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss/1024.0/1024.0\n",
    "    print(\"report mem usage %5.3f MB\" % mem)\n",
    "\n",
    "model_fp32.eval()\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "#torch.quantization.prepare(model_fp32, inplace=True)\n",
    "#print(model_fp32)\n",
    "#model_fp32_fused = torch.quantization.fuse_modules(model_fp32,[[\"conv1\", \"relu\"]],inplace=True)\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32)\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "# compare the sizes\n",
    "f=print_size_of_model(model_fp32,\"fp32\")\n",
    "q=print_size_of_model(model_int8,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))\n",
    "\n",
    "validation_model(model_int8, criterion, optimizer,'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
